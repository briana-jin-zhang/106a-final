{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conservative-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import robosuite as suite\n",
    "from robosuite.environments.manipulation.empty import Empty\n",
    "from scipy import interpolate\n",
    "from robosuite.utils.mjmod import DynamicsModder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rolled-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decent-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan(start_pose, middle_pose, end_pose, horizon):\n",
    "    cs = interpolate.CubicSpline([0, horizon // 2, horizon], [start_pose, middle_pose, end_pose], \n",
    "                                       axis=0, bc_type='clamped')\n",
    "    return cs(range(horizon))  \n",
    "def difference(traj):\n",
    "    traj = np.array(traj)\n",
    "    new_traj = [traj[0]]\n",
    "    for i in range(len(traj)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        new_traj.append(traj[i] - traj[i - 1])\n",
    "    return new_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "headed-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.environments.base.register_env(Empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automatic-kernel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'JOINT_POSITION', 'input_max': 1, 'input_min': -1, 'output_max': 0.05, 'output_min': -0.05, 'kp': 50, 'damping_ratio': 0.1, 'impedance_mode': 'fixed', 'kp_limits': [0, 300], 'damping_ratio_limits': [0, 10], 'qpos_limits': None, 'interpolation': None, 'ramp_ratio': 0.1}\n"
     ]
    }
   ],
   "source": [
    "controller_config = suite.load_controller_config(default_controller=\"JOINT_POSITION\")\n",
    "controller_config[\"damping_ratio\"] = 0.1\n",
    "controller_config[\"ramp_ratio\"] = 0.1\n",
    "print(controller_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "solid-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    }
   ],
   "source": [
    "env = suite.make(\n",
    "    \"Empty\",\n",
    "    robots=\"IIWA\",             # load a Sawyer robot and a Panda robot\n",
    "    gripper_types=\"ClothGripper\",                # use default grippers per robot arm\n",
    "    controller_configs=controller_config, \n",
    "    has_renderer=True,                      # on-screen rendering\n",
    "    render_camera=\"sideview\",              # visualize the \"frontview\" camera\n",
    "    has_offscreen_renderer=False,           # no off-screen rendering\n",
    "    render_collision_mesh=True,\n",
    "    control_freq=20,                        # 20 hz control for applied actions\n",
    "    horizon=horizon,                            # each episode terminates after 200 steps\n",
    "    use_object_obs=False,                   # no observations needed\n",
    "    use_camera_obs=False,                   # no observations needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "superior-abraham",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:03<00:13,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:06<00:10,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:10<00:06,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:13<00:03,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import random\n",
    "\n",
    "num_cloth_joints = 11\n",
    "\n",
    "all_geom_positions = []\n",
    "all_parameters = []\n",
    "for _ in tqdm.tqdm(range(5)):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    \n",
    "    modder = DynamicsModder(sim=env.sim)\n",
    "    damping = random.random() * 20\n",
    "    stiffness = random.random() * 20\n",
    "    all_parameters.append([damping, stiffness])\n",
    "    \n",
    "    for i in range(num_cloth_joints):\n",
    "        modder.mod(\"gripper0_joint\" + str(i), \"damping\", damping)\n",
    "        modder.mod(\"gripper0_joint\" + str(i), \"stiffness\", stiffness)\n",
    "    \n",
    "    geom_positions = []\n",
    "    traj = difference(plan([0, 0, 0, 0, 0, 0, 0], [0, -10, 0, 10, 0, -10, 0], [0, 0, 0, 0, 0, 0, 0], horizon))\n",
    "    while not done:\n",
    "        action = traj[i]\n",
    "        for j in range(num_cloth_joints):\n",
    "            pos = env.sim.data.geom_xpos[env.sim.model.geom_name2id(\"gripper0_g{}_col\".format(j))]\n",
    "            geom_positions.append(pos[0])\n",
    "            geom_positions.append(pos[2])\n",
    "        obs, reward, done, info = env.step(action) \n",
    "#         env.render()\n",
    "    all_geom_positions.append(geom_positions)\n",
    "    \n",
    "all_geom_positions = np.array(all_geom_positions)\n",
    "all_parameters = np.array(all_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scheduled-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have some prior distribution of magazine parameters\n",
    "# Model predicts parameters distribution from actions and movement\n",
    "# Each cycle\n",
    "# Sample parameters and choose actions to minimize entropy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "educational-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DIAYN for trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "understanding-concert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 4400), (5, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_geom_positions.shape, all_parameters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affecting-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_split = 0.8\n",
    "train_length = int(train_split * len(all_geom_positions))\n",
    "val_length = len(all_geom_positions) - train_length\n",
    "all_dataset = torch.utils.data.TensorDataset(torch.from_numpy(all_geom_positions), torch.from_numpy(all_parameters))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(all_dataset, [train_length, val_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "descending-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4400, 2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.1),\n",
    "    torch.nn.Linear(2048, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.1),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 2 * 2),\n",
    ").to(\"cuda\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "functioning-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 36.99732756614685, Val Loss: 13.162463188171387\n",
      "Epoch: 1, Train Loss: 8.291607648134232, Val Loss: 4986111.0\n",
      "Epoch: 2, Train Loss: 407657.73228788376, Val Loss: 5.507568359375\n",
      "Epoch: 3, Train Loss: 6.2811033725738525, Val Loss: 6.350114345550537\n",
      "Epoch: 4, Train Loss: 5.041744589805603, Val Loss: 3.5206222534179688\n",
      "Epoch: 5, Train Loss: 3.3673874735832214, Val Loss: 2.759005069732666\n",
      "Epoch: 6, Train Loss: 2.9817898273468018, Val Loss: 3.1587002277374268\n",
      "Epoch: 7, Train Loss: 3.4947081208229065, Val Loss: 2.5191245079040527\n",
      "Epoch: 8, Train Loss: 2.7493642568588257, Val Loss: 1.9828379154205322\n",
      "Epoch: 9, Train Loss: 2.4707754850387573, Val Loss: 2.1543312072753906\n",
      "Epoch: 10, Train Loss: 2.491608589887619, Val Loss: 2.3578391075134277\n",
      "Epoch: 11, Train Loss: 2.4580265879631042, Val Loss: 2.4599709510803223\n",
      "Epoch: 12, Train Loss: 2.7011000514030457, Val Loss: 1.8945189714431763\n",
      "Epoch: 13, Train Loss: 3.1196702122688293, Val Loss: 1.6788885593414307\n",
      "Epoch: 14, Train Loss: 2.272214710712433, Val Loss: 2.838099479675293\n",
      "Epoch: 15, Train Loss: 2.7954227328300476, Val Loss: 2.678457260131836\n",
      "Epoch: 16, Train Loss: 2.5464630126953125, Val Loss: 2.767772912979126\n",
      "Epoch: 17, Train Loss: 3.8690754175186157, Val Loss: 2.651094913482666\n",
      "Epoch: 18, Train Loss: 2.790980041027069, Val Loss: 3.2308802604675293\n",
      "Epoch: 19, Train Loss: 3.1876699328422546, Val Loss: 3.0449137687683105\n",
      "Epoch: 20, Train Loss: 2.9041833877563477, Val Loss: 2.4349687099456787\n",
      "Epoch: 21, Train Loss: 2.618908315896988, Val Loss: 2.051684856414795\n",
      "Epoch: 22, Train Loss: 2.3551860451698303, Val Loss: 1.8408427238464355\n",
      "Epoch: 23, Train Loss: 2.238182634115219, Val Loss: 1.8563225269317627\n",
      "Epoch: 24, Train Loss: 2.3470772802829742, Val Loss: 1.7736271619796753\n",
      "Epoch: 25, Train Loss: 2.089373469352722, Val Loss: 1.9017062187194824\n",
      "Epoch: 26, Train Loss: 1.9024188816547394, Val Loss: 1.9607733488082886\n",
      "Epoch: 27, Train Loss: 3.3045873641967773, Val Loss: 2.055328607559204\n",
      "Epoch: 28, Train Loss: 2.2645780444145203, Val Loss: 2.41904878616333\n",
      "Epoch: 29, Train Loss: 2.6194268465042114, Val Loss: 2.48563289642334\n",
      "Epoch: 30, Train Loss: 2.542281925678253, Val Loss: 2.1597464084625244\n",
      "Epoch: 31, Train Loss: 2.545106828212738, Val Loss: 1.9316856861114502\n",
      "Epoch: 32, Train Loss: 2.2584580779075623, Val Loss: 2.01558780670166\n",
      "Epoch: 33, Train Loss: 2.313545286655426, Val Loss: 1.9500861167907715\n",
      "Epoch: 34, Train Loss: 2.9427897334098816, Val Loss: 1.935694932937622\n",
      "Epoch: 35, Train Loss: 2.171547383069992, Val Loss: 2.029935836791992\n",
      "Epoch: 36, Train Loss: 2.1263681054115295, Val Loss: 1.7236554622650146\n",
      "Epoch: 37, Train Loss: 1.9482166469097137, Val Loss: 1.651935338973999\n",
      "Epoch: 38, Train Loss: 1.731082022190094, Val Loss: 1.6768691539764404\n",
      "Epoch: 39, Train Loss: 2.0777100324630737, Val Loss: 1.715600609779358\n",
      "Epoch: 40, Train Loss: 2.0105282068252563, Val Loss: 1.7117574214935303\n",
      "Epoch: 41, Train Loss: 1.9565226435661316, Val Loss: 1.7214395999908447\n",
      "Epoch: 42, Train Loss: 1.7896572053432465, Val Loss: 1.7473461627960205\n",
      "Epoch: 43, Train Loss: 2.0524911880493164, Val Loss: 1.8829121589660645\n",
      "Epoch: 44, Train Loss: 2.1014879047870636, Val Loss: 1.8947296142578125\n",
      "Epoch: 45, Train Loss: 1.9432705640792847, Val Loss: 1.7662057876586914\n",
      "Epoch: 46, Train Loss: 2.14429634809494, Val Loss: 1.6947658061981201\n",
      "Epoch: 47, Train Loss: 1.9669758081436157, Val Loss: 1.8777341842651367\n",
      "Epoch: 48, Train Loss: 1.979431390762329, Val Loss: 1.8387367725372314\n",
      "Epoch: 49, Train Loss: 2.123643070459366, Val Loss: 1.7652008533477783\n",
      "Epoch: 50, Train Loss: 2.043987214565277, Val Loss: 1.7766737937927246\n",
      "Epoch: 51, Train Loss: 2.028804063796997, Val Loss: 1.789729356765747\n",
      "Epoch: 52, Train Loss: 1.9924609661102295, Val Loss: 1.77727210521698\n",
      "Epoch: 53, Train Loss: 1.9039790332317352, Val Loss: 1.677380084991455\n",
      "Epoch: 54, Train Loss: 1.9392117261886597, Val Loss: 1.6392371654510498\n",
      "Epoch: 55, Train Loss: 2.0092951357364655, Val Loss: 1.7587214708328247\n",
      "Epoch: 56, Train Loss: 1.920516848564148, Val Loss: 1.7896524667739868\n",
      "Epoch: 57, Train Loss: 1.9046252369880676, Val Loss: 1.7137244939804077\n",
      "Epoch: 58, Train Loss: 1.893867313861847, Val Loss: 1.814766526222229\n",
      "Epoch: 59, Train Loss: 1.9801340997219086, Val Loss: 1.8785178661346436\n",
      "Epoch: 60, Train Loss: 2.0713824927806854, Val Loss: 1.858872890472412\n",
      "Epoch: 61, Train Loss: 1.9403696656227112, Val Loss: 1.7419931888580322\n",
      "Epoch: 62, Train Loss: 1.9117887318134308, Val Loss: 1.6119340658187866\n",
      "Epoch: 63, Train Loss: 1.8469435572624207, Val Loss: 1.5137786865234375\n",
      "Epoch: 64, Train Loss: 2.3008928894996643, Val Loss: 1.8000184297561646\n",
      "Epoch: 65, Train Loss: 2.017178535461426, Val Loss: 1.9996862411499023\n",
      "Epoch: 66, Train Loss: 1.9441910982131958, Val Loss: 1.8886704444885254\n",
      "Epoch: 67, Train Loss: 1.8912819921970367, Val Loss: 1.6457387208938599\n",
      "Epoch: 68, Train Loss: 2.086098164319992, Val Loss: 1.5297482013702393\n",
      "Epoch: 69, Train Loss: 1.855376273393631, Val Loss: 1.5851908922195435\n",
      "Epoch: 70, Train Loss: 1.8511130213737488, Val Loss: 1.795903205871582\n",
      "Epoch: 71, Train Loss: 1.9451223611831665, Val Loss: 1.8896235227584839\n",
      "Epoch: 72, Train Loss: 1.9793925881385803, Val Loss: 1.8816332817077637\n",
      "Epoch: 73, Train Loss: 2.0490952134132385, Val Loss: 1.7809324264526367\n",
      "Epoch: 74, Train Loss: 1.990817815065384, Val Loss: 1.6864818334579468\n",
      "Epoch: 75, Train Loss: 1.935576170682907, Val Loss: 1.6405342817306519\n",
      "Epoch: 76, Train Loss: 1.8906983137130737, Val Loss: 1.678956389427185\n",
      "Epoch: 77, Train Loss: 1.8626673817634583, Val Loss: 1.6169999837875366\n",
      "Epoch: 78, Train Loss: 1.9122425019741058, Val Loss: 1.5084238052368164\n",
      "Epoch: 79, Train Loss: 1.9015020430088043, Val Loss: 1.5084863901138306\n",
      "Epoch: 80, Train Loss: 2.0032464265823364, Val Loss: 1.6420116424560547\n",
      "Epoch: 81, Train Loss: 2.0213202834129333, Val Loss: 1.8191628456115723\n",
      "Epoch: 82, Train Loss: 2.118745982646942, Val Loss: 1.8122048377990723\n",
      "Epoch: 83, Train Loss: 1.9436170756816864, Val Loss: 1.667196273803711\n",
      "Epoch: 84, Train Loss: 1.9752513468265533, Val Loss: 1.6960340738296509\n",
      "Epoch: 85, Train Loss: 2.0570898354053497, Val Loss: 1.8666001558303833\n",
      "Epoch: 86, Train Loss: 1.9313118159770966, Val Loss: 1.8654401302337646\n",
      "Epoch: 87, Train Loss: 2.0118085145950317, Val Loss: 1.7317724227905273\n",
      "Epoch: 88, Train Loss: 1.8943326473236084, Val Loss: 1.6197587251663208\n",
      "Epoch: 89, Train Loss: 1.7991049587726593, Val Loss: 1.5474677085876465\n",
      "Epoch: 90, Train Loss: 2.1243417263031006, Val Loss: 1.6808562278747559\n",
      "Epoch: 91, Train Loss: 1.982200801372528, Val Loss: 1.855404019355774\n",
      "Epoch: 92, Train Loss: 2.057673394680023, Val Loss: 1.8644931316375732\n",
      "Epoch: 93, Train Loss: 2.0018513798713684, Val Loss: 1.8260798454284668\n",
      "Epoch: 94, Train Loss: 2.025792360305786, Val Loss: 1.7594530582427979\n",
      "Epoch: 95, Train Loss: 1.8420920073986053, Val Loss: 1.6741130352020264\n",
      "Epoch: 96, Train Loss: 1.9667499661445618, Val Loss: 1.543466567993164\n",
      "Epoch: 97, Train Loss: 1.8793725967407227, Val Loss: 1.5692188739776611\n",
      "Epoch: 98, Train Loss: 1.9093316197395325, Val Loss: 1.70012629032135\n",
      "Epoch: 99, Train Loss: 1.890550136566162, Val Loss: 1.6944485902786255\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.GaussianNLLLoss()\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for position, target_params in train_dataset:\n",
    "        position = position.to(\"cuda\").float()\n",
    "        target_params = target_params.to(\"cuda\").float()\n",
    "        \n",
    "        pred_params_mu, pred_params_logvar = torch.split(model(position), [2, 2])\n",
    "        loss = loss_fn(pred_params_mu, target_params, torch.exp(pred_params_logvar))\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        for position, target_params in val_dataset:\n",
    "            position = position.to(\"cuda\").float()\n",
    "            target_params = target_params.to(\"cuda\").float()\n",
    "\n",
    "            pred_params_mu, pred_params_logvar = torch.split(model(position), [2, 2])\n",
    "            loss = loss_fn(pred_params_mu, target_params, torch.exp(pred_params_logvar))\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "        \n",
    "    print(\"Epoch: {}, Train Loss: {}, Val Loss: {}\".format(epoch, np.mean(train_losses), np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-cleaner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
