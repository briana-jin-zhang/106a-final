{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conservative-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import robosuite as suite\n",
    "from robosuite.environments.manipulation.empty import Empty\n",
    "from scipy import interpolate\n",
    "from robosuite.utils.mjmod import DynamicsModder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rolled-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decent-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan(start_pose, middle_pose, end_pose, horizon):\n",
    "    cs = interpolate.CubicSpline([0, horizon // 2, horizon], [start_pose, middle_pose, end_pose], \n",
    "                                       axis=0, bc_type='clamped')\n",
    "    return cs(range(horizon))  \n",
    "def difference(traj):\n",
    "    traj = np.array(traj)\n",
    "    new_traj = [traj[0]]\n",
    "    for i in range(len(traj)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        new_traj.append(traj[i] - traj[i - 1])\n",
    "    return new_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "headed-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.environments.base.register_env(Empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automatic-kernel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'JOINT_POSITION', 'input_max': 1, 'input_min': -1, 'output_max': 0.05, 'output_min': -0.05, 'kp': 50, 'damping_ratio': 0.1, 'impedance_mode': 'fixed', 'kp_limits': [0, 300], 'damping_ratio_limits': [0, 10], 'qpos_limits': None, 'interpolation': None, 'ramp_ratio': 0.1}\n"
     ]
    }
   ],
   "source": [
    "controller_config = suite.load_controller_config(default_controller=\"JOINT_POSITION\")\n",
    "controller_config[\"damping_ratio\"] = 0.1\n",
    "controller_config[\"ramp_ratio\"] = 0.1\n",
    "print(controller_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "solid-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    }
   ],
   "source": [
    "env = suite.make(\n",
    "    \"Empty\",\n",
    "    robots=\"IIWA\",             # load a Sawyer robot and a Panda robot\n",
    "    gripper_types=\"ClothGripper\",                # use default grippers per robot arm\n",
    "    controller_configs=controller_config, \n",
    "    has_renderer=True,                      # on-screen rendering\n",
    "    render_camera=\"sideview\",              # visualize the \"frontview\" camera\n",
    "    has_offscreen_renderer=False,           # no off-screen rendering\n",
    "    render_collision_mesh=True,\n",
    "    control_freq=20,                        # 20 hz control for applied actions\n",
    "    horizon=horizon,                            # each episode terminates after 200 steps\n",
    "    use_object_obs=False,                   # no observations needed\n",
    "    use_camera_obs=False,                   # no observations needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "superior-abraham",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:02<00:24,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:05<00:22,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:08<00:20,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:11<00:17,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:14<00:14,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:17<00:12,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:21<00:09,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:24<00:06,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:27<00:03,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import random\n",
    "\n",
    "num_dataset_size = 10\n",
    "num_cloth_joints = 11\n",
    "\n",
    "all_geom_positions = []\n",
    "all_parameters = []\n",
    "for _ in tqdm.tqdm(range(num_dataset_size)):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    \n",
    "    modder = DynamicsModder(sim=env.sim)\n",
    "    damping = random.random() * 20\n",
    "    stiffness = random.random() * 20\n",
    "    all_parameters.append([damping, stiffness])\n",
    "    \n",
    "    for i in range(num_cloth_joints):\n",
    "        modder.mod(\"gripper0_joint\" + str(i), \"damping\", damping)\n",
    "        modder.mod(\"gripper0_joint\" + str(i), \"stiffness\", stiffness)\n",
    "    \n",
    "    geom_positions = []\n",
    "    traj = difference(plan([0, 0, 0, 0, 0, 0, 0], [0, -10, 0, 10, 0, -10, 0], [0, 0, 0, 0, 0, 0, 0], horizon))\n",
    "    while not done:\n",
    "        action = traj[i]\n",
    "        for j in range(num_cloth_joints):\n",
    "            pos = env.sim.data.geom_xpos[env.sim.model.geom_name2id(\"gripper0_g{}_col\".format(j))]\n",
    "            geom_positions.append(pos[0])\n",
    "            geom_positions.append(pos[2])\n",
    "        obs, reward, done, info = env.step(action) \n",
    "#         env.render()\n",
    "    all_geom_positions.append(geom_positions)\n",
    "    \n",
    "all_geom_positions = np.array(all_geom_positions)\n",
    "all_parameters = np.array(all_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scheduled-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have some prior distribution of magazine parameters\n",
    "# Model predicts parameters distribution from actions and movement\n",
    "# Each cycle\n",
    "# Sample parameters and choose actions to minimize entropy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "educational-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DIAYN for trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "understanding-concert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 4400), (10, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_geom_positions.shape, all_parameters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "toxic-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_geom_positions.npy\", 'wb') as f:\n",
    "    np.save(f, all_geom_positions)\n",
    "with open(\"all_parameters.npy\", 'wb') as f:\n",
    "    np.save(f, all_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "affecting-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_split = 0.8\n",
    "train_length = int(train_split * len(all_geom_positions))\n",
    "val_length = len(all_geom_positions) - train_length\n",
    "all_dataset = torch.utils.data.TensorDataset(torch.from_numpy(all_geom_positions), torch.from_numpy(all_parameters))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(all_dataset, [train_length, val_length])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "descending-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4400, 2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.1),\n",
    "    torch.nn.Linear(2048, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.1),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 2 * 2),\n",
    ").to(\"cuda\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "functioning-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 51.0892333984375, Val Loss: 36.040279388427734\n",
      "Epoch: 1, Train Loss: 40.13995361328125, Val Loss: 26.40574073791504\n",
      "Epoch: 2, Train Loss: 30.54589080810547, Val Loss: 18.04074478149414\n",
      "Epoch: 3, Train Loss: 20.626604080200195, Val Loss: 11.60287857055664\n",
      "Epoch: 4, Train Loss: 13.423412322998047, Val Loss: 7.234892845153809\n",
      "Epoch: 5, Train Loss: 8.205706596374512, Val Loss: 4.618354797363281\n",
      "Epoch: 6, Train Loss: 5.3087263107299805, Val Loss: 3.3003220558166504\n",
      "Epoch: 7, Train Loss: 3.5358190536499023, Val Loss: 2.803720474243164\n",
      "Epoch: 8, Train Loss: 2.9595046043395996, Val Loss: 2.7505319118499756\n",
      "Epoch: 9, Train Loss: 2.833864450454712, Val Loss: 2.9104185104370117\n",
      "Epoch: 10, Train Loss: 2.95281720161438, Val Loss: 3.159301280975342\n",
      "Epoch: 11, Train Loss: 3.220903158187866, Val Loss: 3.432943105697632\n",
      "Epoch: 12, Train Loss: 3.4770543575286865, Val Loss: 3.7004036903381348\n",
      "Epoch: 13, Train Loss: 3.681475877761841, Val Loss: 3.9469563961029053\n",
      "Epoch: 14, Train Loss: 3.9833080768585205, Val Loss: 4.1646246910095215\n",
      "Epoch: 15, Train Loss: 4.191916465759277, Val Loss: 4.349757671356201\n",
      "Epoch: 16, Train Loss: 4.461333751678467, Val Loss: 4.500476837158203\n",
      "Epoch: 17, Train Loss: 4.521982192993164, Val Loss: 4.617963790893555\n",
      "Epoch: 18, Train Loss: 4.713223457336426, Val Loss: 4.701976299285889\n",
      "Epoch: 19, Train Loss: 4.730235576629639, Val Loss: 4.755536079406738\n",
      "Epoch: 20, Train Loss: 4.80134391784668, Val Loss: 4.780273914337158\n",
      "Epoch: 21, Train Loss: 4.891545295715332, Val Loss: 4.777632236480713\n",
      "Epoch: 22, Train Loss: 4.815584182739258, Val Loss: 4.74949836730957\n",
      "Epoch: 23, Train Loss: 4.718947410583496, Val Loss: 4.69804573059082\n",
      "Epoch: 24, Train Loss: 4.755616664886475, Val Loss: 4.625400066375732\n",
      "Epoch: 25, Train Loss: 4.66355037689209, Val Loss: 4.535297393798828\n",
      "Epoch: 26, Train Loss: 4.541387557983398, Val Loss: 4.430484771728516\n",
      "Epoch: 27, Train Loss: 4.4710235595703125, Val Loss: 4.313331127166748\n",
      "Epoch: 28, Train Loss: 4.369565010070801, Val Loss: 4.185672283172607\n",
      "Epoch: 29, Train Loss: 4.242579936981201, Val Loss: 4.048169136047363\n",
      "Epoch: 30, Train Loss: 4.086569786071777, Val Loss: 3.903223752975464\n",
      "Epoch: 31, Train Loss: 3.993349552154541, Val Loss: 3.752458333969116\n",
      "Epoch: 32, Train Loss: 3.823176383972168, Val Loss: 3.598349094390869\n",
      "Epoch: 33, Train Loss: 3.6620211601257324, Val Loss: 3.443096160888672\n",
      "Epoch: 34, Train Loss: 3.4660587310791016, Val Loss: 3.2886857986450195\n",
      "Epoch: 35, Train Loss: 3.3728904724121094, Val Loss: 3.138692855834961\n",
      "Epoch: 36, Train Loss: 3.189443588256836, Val Loss: 2.9954683780670166\n",
      "Epoch: 37, Train Loss: 3.0344979763031006, Val Loss: 2.8651280403137207\n",
      "Epoch: 38, Train Loss: 2.8739264011383057, Val Loss: 2.7560853958129883\n",
      "Epoch: 39, Train Loss: 2.8330183029174805, Val Loss: 2.6749770641326904\n",
      "Epoch: 40, Train Loss: 2.7422127723693848, Val Loss: 2.6301567554473877\n",
      "Epoch: 41, Train Loss: 2.6610941886901855, Val Loss: 2.629920244216919\n",
      "Epoch: 42, Train Loss: 2.7410287857055664, Val Loss: 2.670250654220581\n",
      "Epoch: 43, Train Loss: 2.7554166316986084, Val Loss: 2.7347841262817383\n",
      "Epoch: 44, Train Loss: 2.794814348220825, Val Loss: 2.785461902618408\n",
      "Epoch: 45, Train Loss: 2.884645938873291, Val Loss: 2.7954087257385254\n",
      "Epoch: 46, Train Loss: 2.8365001678466797, Val Loss: 2.7630796432495117\n",
      "Epoch: 47, Train Loss: 2.7588305473327637, Val Loss: 2.7090320587158203\n",
      "Epoch: 48, Train Loss: 2.6646227836608887, Val Loss: 2.659237861633301\n",
      "Epoch: 49, Train Loss: 2.7758336067199707, Val Loss: 2.6139440536499023\n",
      "Epoch: 50, Train Loss: 2.6292738914489746, Val Loss: 2.577796459197998\n",
      "Epoch: 51, Train Loss: 2.697438955307007, Val Loss: 2.555807590484619\n",
      "Epoch: 52, Train Loss: 2.6449782848358154, Val Loss: 2.544888496398926\n",
      "Epoch: 53, Train Loss: 2.5719871520996094, Val Loss: 2.5408878326416016\n",
      "Epoch: 54, Train Loss: 2.5689663887023926, Val Loss: 2.5406339168548584\n",
      "Epoch: 55, Train Loss: 2.6176557540893555, Val Loss: 2.541700839996338\n",
      "Epoch: 56, Train Loss: 2.5814015865325928, Val Loss: 2.543898344039917\n",
      "Epoch: 57, Train Loss: 2.5653934478759766, Val Loss: 2.5450491905212402\n",
      "Epoch: 58, Train Loss: 2.577867031097412, Val Loss: 2.5440478324890137\n",
      "Epoch: 59, Train Loss: 2.5939126014709473, Val Loss: 2.541630744934082\n",
      "Epoch: 60, Train Loss: 2.5844221115112305, Val Loss: 2.5365958213806152\n",
      "Epoch: 61, Train Loss: 2.5596909523010254, Val Loss: 2.5289483070373535\n",
      "Epoch: 62, Train Loss: 2.5550379753112793, Val Loss: 2.5187010765075684\n",
      "Epoch: 63, Train Loss: 2.5185914039611816, Val Loss: 2.506040096282959\n",
      "Epoch: 64, Train Loss: 2.5267927646636963, Val Loss: 2.4919850826263428\n",
      "Epoch: 65, Train Loss: 2.5082972049713135, Val Loss: 2.4787464141845703\n",
      "Epoch: 66, Train Loss: 2.491428852081299, Val Loss: 2.4667022228240967\n",
      "Epoch: 67, Train Loss: 2.4563815593719482, Val Loss: 2.4578356742858887\n",
      "Epoch: 68, Train Loss: 2.4442684650421143, Val Loss: 2.451185464859009\n",
      "Epoch: 69, Train Loss: 2.4345459938049316, Val Loss: 2.4475467205047607\n",
      "Epoch: 70, Train Loss: 2.418849468231201, Val Loss: 2.448235034942627\n",
      "Epoch: 71, Train Loss: 2.384474515914917, Val Loss: 2.4516618251800537\n",
      "Epoch: 72, Train Loss: 2.3785996437072754, Val Loss: 2.457510471343994\n",
      "Epoch: 73, Train Loss: 2.391852855682373, Val Loss: 2.465484380722046\n",
      "Epoch: 74, Train Loss: 2.3680436611175537, Val Loss: 2.4750146865844727\n",
      "Epoch: 75, Train Loss: 2.393707275390625, Val Loss: 2.4815258979797363\n",
      "Epoch: 76, Train Loss: 2.3446531295776367, Val Loss: 2.4885454177856445\n",
      "Epoch: 77, Train Loss: 2.392788887023926, Val Loss: 2.4925742149353027\n",
      "Epoch: 78, Train Loss: 2.377042770385742, Val Loss: 2.496009349822998\n",
      "Epoch: 79, Train Loss: 2.3180041313171387, Val Loss: 2.4990062713623047\n",
      "Epoch: 80, Train Loss: 2.3103246688842773, Val Loss: 2.4996397495269775\n",
      "Epoch: 81, Train Loss: 2.2828311920166016, Val Loss: 2.502387523651123\n",
      "Epoch: 82, Train Loss: 2.3076705932617188, Val Loss: 2.5043857097625732\n",
      "Epoch: 83, Train Loss: 2.314392566680908, Val Loss: 2.505950450897217\n",
      "Epoch: 84, Train Loss: 2.2920660972595215, Val Loss: 2.508270740509033\n",
      "Epoch: 85, Train Loss: 2.3117144107818604, Val Loss: 2.508841037750244\n",
      "Epoch: 86, Train Loss: 2.3095474243164062, Val Loss: 2.510331153869629\n",
      "Epoch: 87, Train Loss: 2.2739334106445312, Val Loss: 2.5119218826293945\n",
      "Epoch: 88, Train Loss: 2.2895162105560303, Val Loss: 2.513808250427246\n",
      "Epoch: 89, Train Loss: 2.3050217628479004, Val Loss: 2.5167880058288574\n",
      "Epoch: 90, Train Loss: 2.2837181091308594, Val Loss: 2.5225725173950195\n",
      "Epoch: 91, Train Loss: 2.31201434135437, Val Loss: 2.529067039489746\n",
      "Epoch: 92, Train Loss: 2.2916550636291504, Val Loss: 2.536405563354492\n",
      "Epoch: 93, Train Loss: 2.2905588150024414, Val Loss: 2.5428338050842285\n",
      "Epoch: 94, Train Loss: 2.2964487075805664, Val Loss: 2.5508928298950195\n",
      "Epoch: 95, Train Loss: 2.2824268341064453, Val Loss: 2.5601561069488525\n",
      "Epoch: 96, Train Loss: 2.2858290672302246, Val Loss: 2.568145513534546\n",
      "Epoch: 97, Train Loss: 2.2794346809387207, Val Loss: 2.579986095428467\n",
      "Epoch: 98, Train Loss: 2.271606206893921, Val Loss: 2.587047576904297\n",
      "Epoch: 99, Train Loss: 2.3009862899780273, Val Loss: 2.5883378982543945\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.GaussianNLLLoss()\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for position, target_params in train_loader:\n",
    "        position = position.to(\"cuda\").float()\n",
    "        target_params = target_params.to(\"cuda\").float()\n",
    "        \n",
    "        pred_params_mu, pred_params_logvar = torch.split(model(position), 2, dim=1)\n",
    "        loss = loss_fn(pred_params_mu, target_params, torch.exp(pred_params_logvar))\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        for position, target_params in val_loader:\n",
    "            position = position.to(\"cuda\").float()\n",
    "            target_params = target_params.to(\"cuda\").float()\n",
    "\n",
    "            pred_params_mu, pred_params_logvar = torch.split(model(position), 2, dim=1)\n",
    "            loss = loss_fn(pred_params_mu, target_params, torch.exp(pred_params_logvar))\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "        \n",
    "    print(\"Epoch: {}, Train Loss: {}, Val Loss: {}\".format(epoch, np.mean(train_losses), np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "noted-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "ground_truth = []\n",
    "for i, (position, target_params) in enumerate(val_loader):\n",
    "    prediction, _ = torch.split(model(position.to(\"cuda\").float()), 2, dim=1)\n",
    "    predictions.append(prediction.detach().cpu().numpy())\n",
    "    ground_truth.append(target_params.cpu().numpy())\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "ground_truth = np.concatenate(ground_truth, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "strong-houston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(ground_truth[:, 0], predictions[:, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "selected-rapid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(ground_truth[:, 1], predictions[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-adjustment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
